{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "## What are neural networks?\n",
    "A neural network is a machine learing training algorithm which is loosely based on the working of the human brain. A neural network has input nodes where we pass feature values which are passed through layers after which we give the output in terms of output nodes.\n",
    "<img src=\"neural_nets.png\" height=600 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "In neural networks, an activation function refers to the function that is applied on the data when it is passed forward. It is the computation that occurs due to which information is carried forward in the neural network.\n",
    "<img src=\"activation-functions.png\" height=600 width=600>\n",
    "<img src=\"activation-function.png\" height=600 width=600>\n",
    "\n",
    "## Weights\n",
    "Weights basically tell us **how important a particular feature is for the model**. A neural network learns on the basis of these weights. The values assigned to each weight is random initially. We ususally have it in the form of a matrix or a vector. We will discuss how it changes soon.\n",
    "\n",
    "## Input Layer\n",
    "This is the layer where we input the signals or features or in even simpler terms, the input layer is **X**. We pass in values to this layer after which, the network passes them forward.\n",
    "\n",
    "## Hidden Layers\n",
    "These are the layers where the magic happens. They basically have nodes where activation fucntions are applied. On applying these functions, we get outputs which are passed on to further nodes.\n",
    "\n",
    "## Output Layer\n",
    "This is the final layer in the neural network model. The output is calulated or shown in this layer. We get the output in the form of a continuous value or a class depending on the task at hand.\n",
    "\n",
    "## Forward Propogation\n",
    "Also known as forward pass, this is the process of passing the data forward through the neural network to get an output for that layer. It is also referred to as inference.\n",
    "\n",
    "## Backpropogation\n",
    "Possibly the most important topic in this topic, backpropogation is the process of checking the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize values\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "# Divide each element of X by an array with max of each column\n",
    "X = X / np.max(X, axis=0) \n",
    "# Divide each element of y by 100\n",
    "y = y / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  # The np.exp works like e^x where e is eulers constant \n",
    "\n",
    "def sigmoid_derive(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise values\n",
    "epoch=1000\n",
    "learning_rate = 0.2\n",
    "input_nodes = 2\n",
    "hidden_nodes = 3 \n",
    "output_nodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of hidden layer\n",
    "wh = np.random.uniform(size = (input_nodes, hidden_nodes))\n",
    "# Weight of output layer\n",
    "wout=np.random.uniform(size = (hidden_nodes, output_nodes)) \n",
    "\n",
    "# Bias of hidden layer\n",
    "bh = np.random.uniform(size = (1, hidden_nodes))\n",
    "# Bias of output layer\n",
    "bout=np.random.uniform(size = (1, output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training starts\n",
    "for i in range(epoch):\n",
    "\t# Sum of (input * weights in hidden layer) + bias of hidden layer\n",
    "    h_ip = np.dot(X, wh) + bh\n",
    "\n",
    "    # Apply Activation Function\n",
    "    h_out = sigmoid(h_ip)\n",
    "\n",
    "    # Sum of (o/p of hidden layer * weights of output layer) + bias of output layer\n",
    "    o_ip = np.dot(h_out, wout) + bout\n",
    "    \n",
    "    # Apply Activation Function\n",
    "    o_out = sigmoid(o_ip)\n",
    "\n",
    "    # Delta of o/p layer\n",
    "    delta_o = (y - o_out) * sigmoid_derive(o_out)\n",
    "    \n",
    "    # Delta of hidden layer\n",
    "    delta_h = delta_o.dot(wout.T) * sigmoid_derive(h_out)\n",
    "    \n",
    "    # Update the weights\n",
    "    wout += h_out.T.dot(delta_o) * learning_rate\n",
    "    wh += X.T.dot(delta_h) * learning_rate\n",
    "\n",
    "    # error = sum(deltaK) ** 2 / len(deltaK)    \n",
    "    # print(\"Epoch -> {0}, learning_rate -> {1}, error_rate -> {2}\".format(i, learning_rate, error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
